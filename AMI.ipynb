{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "import xgboost as xgb\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_prevalence(y_actual):\n",
    "    return (sum(y_actual)/len(y_actual))\n",
    "\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    \n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    f1score = f1_score(y_actual, y_pred > thresh)\n",
    "    \n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('f1_score:%.3f'%f1score)\n",
    "\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity, f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./AMI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.distplot(df['Age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 单列特征与标签的关系\n",
    "# 不同年龄段，患心脏病和不患的分布图\n",
    "pd.crosstab(df.Age,df.expire_flag).plot(kind='bar',figsize=(6,3))\n",
    "plt.title(\"HeartDiseaseAndAge\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"HeartDiseaseAndAge.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(df.Sex,df.expire_flag).plot(kind=\"bar\",figsize=(4,3),color=['#1CA53B',\"#AA1111\"])\n",
    "plt.title(\"HeartDiseaseAndAge\")\n",
    "plt.xlabel(\"Sex\")\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend([\"Haven not Disease\",\"Have Disease\"])\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.savefig(\"HeartDiseaseAndAge.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(x=\"expire_flag\",y=\"Age\",hue=\"Sex\",data=df,split=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=1)\n",
    "\n",
    "y_train = train_data.expire_flag\n",
    "X_train = train_data.drop(['expire_flag'], axis=1)\n",
    "\n",
    "y_test = test_data.expire_flag\n",
    "X_test = test_data.drop(['expire_flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "ss = StandardScaler()\n",
    "X_train_s = ss.fit_transform(X_train)\n",
    "X_test_s = ss.transform(X_test)\n",
    "\n",
    "mm = MinMaxScaler()\n",
    "X_train_m = mm.fit_transform(X_train)\n",
    "X_test_m = mm.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table-One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c = train_data.copy()\n",
    "test_c = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_c['group'] = 1\n",
    "test_c['group'] = 2\n",
    "merge_df = pd.concat([train_c, test_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['Sex', 'Race', 'Insurance', 'Marital_status', 'First_careunit', 'Hypertension', \n",
    "               'MI_history', 'PCI','Bypass','Drug', '90Status']\n",
    "\n",
    "nonnormal =  list(set(columns).difference(set(categorical)))\n",
    "print(nonnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tableone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = '90Status'\n",
    "mytable = tableone.TableOne(\n",
    "    df, columns, categorical, groupby, \n",
    "    nonnormal, pval=True, label_suffix=True,htest_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytable.to_csv('./table_one.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full variable model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN \n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.metrics import accuracy_score  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import scale  \n",
    "\n",
    "# SVM\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn import svm \n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state = 42)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = lr.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Logistic Regression')\n",
    "print('Training:')\n",
    "thresh = 0.5\n",
    "lr_train_auc, lr_train_accuracy, lr_train_recall, \\\n",
    "    lr_train_precision, lr_train_specificity, lr_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "lr_valid_auc, lr_valid_accuracy, lr_valid_recall, \\\n",
    "    lr_valid_precision, lr_valid_specificity, lr_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ada_cv(n_estimators, learning_rate):\n",
    "    val = cross_val_score(\n",
    "        AdaBoostClassifier(n_estimators=int(n_estimators), \n",
    "                           learning_rate=learning_rate,\n",
    "                           random_state=42), \n",
    "        X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "ada_bo = BayesianOptimization(\n",
    "    ada_cv,\n",
    "    {'n_estimators': (1, 500),\n",
    "     'learning_rate': (0.01, 0.999)}\n",
    ")\n",
    "\n",
    "ada_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaboost = AdaBoostClassifier(learning_rate=min(ada_bo.max['params']['learning_rate'], 0.999), \n",
    "                              n_estimators=int(ada_bo.max['params']['n_estimators']), \n",
    "                              random_state=42)\n",
    "adaboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = adaboost.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = adaboost.predict_proba(X_test)[:,1]\n",
    "thresh = 0.5\n",
    "\n",
    "print('Adaboost')\n",
    "print('Training:')\n",
    "ada_train_auc, ada_train_accuracy, ada_train_recall, \\\n",
    "    ada_train_precision, ada_train_specificity, ada_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "ada_valid_auc, ada_valid_accuracy, ada_valid_recall, \\\n",
    "    ada_valid_precision, ada_valid_specificity, ada_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = adaboost.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = adaboost.predict_proba(X_test)[:,1]\n",
    "thresh = 0.5\n",
    "\n",
    "print('Adaboost')\n",
    "print('Training:')\n",
    "ada_train_auc, ada_train_accuracy, ada_train_recall, \\\n",
    "    ada_train_precision, ada_train_specificity, ada_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "ada_valid_auc, ada_valid_accuracy, ada_valid_recall, \\\n",
    "    ada_valid_precision, ada_valid_specificity, ada_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_cv(n_neighbors):\n",
    "    val = cross_val_score(KNN(n_neighbors = int(n_neighbors)),\n",
    "        X_train_m, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "knn_bo = BayesianOptimization(\n",
    "    knn_cv,\n",
    "    {'n_neighbors': (1, 500)}\n",
    ")\n",
    "\n",
    "knn_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNN(n_neighbors = int(knn_bo.max['params']['n_neighbors']))\n",
    "knn.fit(scale(X_train_m), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = knn.predict_proba(scale(X_train_m))[:,1]\n",
    "y_valid_preds = knn.predict_proba(scale(X_test_m))[:,1]\n",
    "thresh = 0.5\n",
    "print('KNN')\n",
    "print('Training:')\n",
    "knn_train_auc, knn_train_accuracy, knn_train_recall, \\\n",
    "    knn_train_precision, knn_train_specificity, knn_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "knn_valid_auc, knn_valid_accuracy, knn_valid_recall, \\\n",
    "    knn_valid_precision, knn_valid_specificity, knn_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True))\n",
    "svm.fit(X_train_m, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = svm.decision_function(X_train_m)\n",
    "y_valid_preds = svm.decision_function(X_test_m)\n",
    "thresh = 0.5\n",
    "\n",
    "print('SVM')\n",
    "print('Training:')\n",
    "svm_train_auc, svm_train_accuracy, svm_train_recall, \\\n",
    "    svm_train_precision, svm_train_specificity, svm_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "svm_valid_auc, svm_valid_accuracy, svm_valid_recall, \\\n",
    "    svm_valid_precision, svm_valid_specificity, svm_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB(alpha=0.001)\n",
    "mnb.fit(X_train_m, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = mnb.predict_proba(X_train_m)[:, 1]\n",
    "y_valid_preds = mnb.predict_proba(X_test_m)[:, 1]\n",
    "thresh = 0.5\n",
    "print('MNB')\n",
    "print('Training:')\n",
    "mnb_train_auc, mnb_train_accuracy, mnb_train_recall, \\\n",
    "    mnb_train_precision, mnb_train_specificity, mnb_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "mnb_valid_auc, mnb_valid_accuracy, mnb_valid_recall, \\\n",
    "    mnb_valid_precision, mnb_valid_specificity, mnb_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgb_cv(n_estimators, max_depth, learning_rate):\n",
    "    val = cross_val_score(\n",
    "        xgb.XGBRegressor(max_depth=int(max_depth), \n",
    "                         learning_rate=min(learning_rate, 0.999), \n",
    "                         n_estimators=int(n_estimators),\n",
    "                         random_state=42), \n",
    "        X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "xgb_bo = BayesianOptimization(\n",
    "    xgb_cv,\n",
    "    {'n_estimators': (10, 1000),\n",
    "     'learning_rate': (0.001, 0.999),\n",
    "     'max_depth': (1, 150)}\n",
    ")\n",
    "\n",
    "xgb_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = xgb_bo.max['params']['learning_rate']\n",
    "max_depth = xgb_bo.max['params']['max_depth']\n",
    "n_estimators = xgb_bo.max['params']['n_estimators']\n",
    "\n",
    "xgre = xgb.XGBRegressor(n_estimators=int(n_estimators),\n",
    "                        learning_rate=min(learning_rate, 0.999),  # float\n",
    "                        max_depth=int(max_depth),\n",
    "                        random_state=2)\n",
    "xgre.fit(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = xgre.predict(X_train)\n",
    "y_valid_preds = xgre.predict(X_test)\n",
    "thresh=0.5\n",
    "print('XGBoost')\n",
    "print('Training:')\n",
    "xgre_train_auc, xgre_train_accuracy, xgre_train_recall, \\\n",
    "    xgre_train_precision, xgre_train_specificity, xgre_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "xgre_valid_auc, xgre_valid_accuracy, xgre_valid_recall, \\\n",
    "    xgre_valid_precision, xgre_valid_specificity, xgre_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_train_m, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = nb.predict_proba(X_train_m)[:,1]\n",
    "y_valid_preds = nb.predict_proba(X_test_m)[:,1]\n",
    "\n",
    "print('Naive Bayes')\n",
    "print('Training:')\n",
    "nb_train_auc, nb_train_accuracy, nb_train_recall, nb_train_precision, nb_train_specificity, nb_train_f1 =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "nb_valid_auc, nb_valid_accuracy, nb_valid_recall, nb_valid_precision, nb_valid_specificity, nb_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score_list = []\n",
    "for i in range(40):\n",
    "    tree = DecisionTreeClassifier(max_depth =i, random_state = 42)\n",
    "    score = cross_val_score(tree, X_train, y_train, cv=10, scoring='roc_auc').mean()\n",
    "    score_list.append(score)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(range(0,len(score_list)), score_list)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('score')   # 通过图像选择最好的参数\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth =12, random_state = 42)\n",
    "tree.fit(X_train_m, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = tree.predict_proba(X_train_m)[:,1]\n",
    "y_valid_preds = tree.predict_proba(X_test_m)[:,1]\n",
    "\n",
    "print('Decision Tree')\n",
    "print('Training:')\n",
    "tree_train_auc, tree_train_accuracy, tree_train_recall, tree_train_precision, tree_train_specificity, tree_train_f1 =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "tree_valid_auc, tree_valid_accuracy, tree_valid_recall, tree_valid_precision, tree_valid_specificity, tree_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(n_estimators, min_samples_split, max_features, max_depth):\n",
    "    val = cross_val_score(\n",
    "        RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        ), X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "rf_bo = BayesianOptimization(\n",
    "    rf_cv,\n",
    "    {'n_estimators': (10, 200),\n",
    "     'min_samples_split': (2, 25),\n",
    "     'max_features': (0.1, 0.999),\n",
    "     'max_depth': (5, 10)}\n",
    ")\n",
    "\n",
    "rf_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = rf_bo.max['params']['max_features']\n",
    "max_depth = rf_bo.max['params']['max_depth']\n",
    "n_estimators = rf_bo.max['params']['n_estimators']\n",
    "min_samples_split = rf_bo.max['params']['min_samples_split']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = rf.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_test)[:,1]\n",
    "thresh = 0.5\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity, rf_train_f1 =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "rf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, rf_valid_specificity, rf_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "def gbc_cv(n_estimators, max_depth, learning_rate):\n",
    "    val = cross_val_score(\n",
    "        GradientBoostingClassifier(max_depth=int(max_depth), \n",
    "                         learning_rate=min(learning_rate, 0.999), \n",
    "                         n_estimators=int(n_estimators)), \n",
    "        X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "gbc_bo = BayesianOptimization(\n",
    "    gbc_cv,\n",
    "    {'n_estimators': (1, 50),\n",
    "     'learning_rate': (0.001, 0.999),\n",
    "     'max_depth': (1, 5)}\n",
    ")\n",
    "\n",
    "gbc_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc = GradientBoostingClassifier(\n",
    "    n_estimators=int(gbc_bo.max['params']['n_estimators']), \n",
    "    learning_rate=min(gbc_bo.max['params']['learning_rate'], 0.999), \n",
    "    max_depth=int(gbc_bo.max['params']['max_depth']), random_state=42)\n",
    "gbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = gbc.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = gbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "print('Gradient Boosting Classifier')\n",
    "print('Training:')\n",
    "gbc_train_auc, gbc_train_accuracy, gbc_train_recall, gbc_train_precision, gbc_train_specificity, gbc_train_f1 = print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "gbc_valid_auc, gbc_valid_accuracy, gbc_valid_recall, gbc_valid_precision, gbc_valid_specificity, gbc_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrate model evaluation results and compare them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(\n",
    "    {'classifier':['Ada', 'Ada', 'KNN', 'KNN', 'SVM', 'SVM', 'MNB', 'MNB','XGB', 'XGB',\n",
    "                   'LR', 'LR', 'NB','NB','DT','DT','RF','RF','GB','GB'],\n",
    "     'data_set':['train','valid']*10,\n",
    "     'auc':[ada_train_auc,  ada_valid_auc,\n",
    "            knn_train_auc,  knn_valid_auc,\n",
    "            svm_train_auc,  svm_valid_auc, \n",
    "            mnb_train_auc,  mnb_valid_auc, \n",
    "            xgre_train_auc, xgre_valid_auc, \n",
    "            lr_train_auc,   lr_valid_auc,\n",
    "            nb_train_auc,   nb_valid_auc,\n",
    "            tree_train_auc, tree_valid_auc,\n",
    "            rf_train_auc,   rf_valid_auc,\n",
    "            gbc_train_auc,  gbc_valid_auc],\n",
    "     'accuracy':[ada_train_accuracy, ada_valid_accuracy,\n",
    "                 knn_train_accuracy, knn_valid_accuracy,\n",
    "                 svm_train_accuracy, svm_valid_accuracy, \n",
    "                 mnb_train_accuracy, mnb_valid_accuracy, \n",
    "                 xgre_train_accuracy, xgre_valid_accuracy, \n",
    "                 lr_train_accuracy,lr_valid_accuracy,\n",
    "                 nb_train_accuracy,nb_valid_accuracy,\n",
    "                 tree_train_accuracy,tree_valid_accuracy,\n",
    "                 rf_train_accuracy,rf_valid_accuracy,\n",
    "                 gbc_train_accuracy,gbc_valid_accuracy],\n",
    "     'recall':[ada_train_recall, ada_valid_recall,\n",
    "               knn_train_recall, knn_valid_recall,\n",
    "               svm_train_recall, svm_valid_recall, \n",
    "               mnb_train_recall, mnb_valid_recall, \n",
    "               xgre_train_recall, xgre_valid_recall, \n",
    "               lr_train_recall,lr_valid_recall,\n",
    "               nb_train_recall,nb_valid_recall,\n",
    "               tree_train_recall,tree_valid_recall,\n",
    "               rf_train_recall,rf_valid_recall,\n",
    "               gbc_train_recall,gbc_valid_recall],  \n",
    "     'precision':[ada_train_precision, ada_valid_precision, \n",
    "                  knn_train_precision, knn_valid_precision, \n",
    "                  svm_train_precision, svm_valid_precision, \n",
    "                  mnb_train_precision, mnb_valid_precision, \n",
    "                  xgre_train_precision, xgre_valid_precision, \n",
    "                  lr_train_precision,lr_valid_precision,\n",
    "                  nb_train_precision,nb_valid_precision,\n",
    "                  tree_train_precision,tree_valid_precision,\n",
    "                  rf_train_precision,rf_valid_precision,\n",
    "                  gbc_train_precision,gbc_valid_precision],   \n",
    "     'specificity':[ada_train_specificity, ada_valid_specificity, \n",
    "                    knn_train_specificity, knn_valid_specificity,\n",
    "                    svm_train_specificity, svm_valid_specificity, \n",
    "                    mnb_train_specificity, mnb_valid_specificity, \n",
    "                    xgre_train_specificity, xgre_valid_specificity, \n",
    "                    lr_train_specificity,lr_valid_specificity,\n",
    "                    nb_train_specificity,nb_valid_specificity,\n",
    "                    tree_train_specificity,tree_valid_specificity,\n",
    "                    rf_train_specificity,rf_valid_specificity,\n",
    "                    gbc_train_specificity,gbc_valid_specificity],\n",
    "     'f1_score':[ada_train_f1, ada_test_f1, \n",
    "                 knn_train_f1, knn_test_f1,\n",
    "                 svm_train_f1, svm_test_f1, \n",
    "                 mnb_train_f1, mnb_test_f1, \n",
    "                 xgre_train_f1, xgre_test_f1, \n",
    "                 lr_train_f1,lr_test_f1,\n",
    "                 nb_train_f1,nb_test_f1,\n",
    "                 tree_train_f1,tree_test_f1,\n",
    "                 rf_train_f1,rf_test_f1,\n",
    "                 gbc_train_f1,gbc_test_f1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[df_results.data_set == 'train']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[df_results.data_set == 'train'].to_csv('./figure/10_model_train_evaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[df_results.data_set == 'valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.loc[df_results.data_set == 'valid'].to_csv('./figure/10_model_valid_evaluate.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.barplot(x=\"classifier\", y=\"recall\", hue=\"data_set\", data=df_results)\n",
    "ax.set_xlabel('Classifier',fontsize = 15)\n",
    "ax.set_ylabel('AUC', fontsize = 15)\n",
    "ax.tick_params(labelsize=15)\n",
    "\n",
    "# Put the legend out of the figure\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0., fontsize = 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose a model to rebuild\n",
    "\n",
    "Make K-fold calibration ROC chart, PR chart, variable importance chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(n_estimators, min_samples_split, max_depth):\n",
    "    val = cross_val_score(\n",
    "        RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        ), X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "rf_bo = BayesianOptimization(\n",
    "    rf_cv,\n",
    "    {'n_estimators': (10, 1000),\n",
    "     'min_samples_split': (2, 10),\n",
    "     'max_depth': (2, 150)}\n",
    ")\n",
    "\n",
    "rf_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rfpimp import plot_corr_heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = plot_corr_heatmap(X_train, figsize=(15,10))\n",
    "viz.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features = rf_bo.max['params']['max_features']\n",
    "max_depth = rf_bo.max['params']['max_depth']\n",
    "n_estimators = rf_bo.max['params']['n_estimators']\n",
    "min_samples_split = rf_bo.max['params']['min_samples_split']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            n_jobs = -1,\n",
    "            oob_score = True,\n",
    "            bootstrap = True,\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_valid_preds = rf.predict_proba(X_test)[:,1]\n",
    "rf_valid_auc_base = roc_auc_score(y_test, y_valid_preds)\n",
    "\n",
    "print('Validation AUC:%.3f'%(rf_valid_auc_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from rfpimp import permutation_importances\n",
    "\n",
    "def r2(rf, X_train, y_train):\n",
    "    return r2_score(y_train, rf.predict(X_train))\n",
    "\n",
    "perm_imp_rfpimp = permutation_importances(rf, X_train, y_train, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perm_imp_rfpimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train.drop('Age', axis = 1), y_train)\n",
    "drop_col_score = rf.score(X_train.drop('Age', axis = 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone \n",
    "\n",
    "def drop_col_feat_imp(model, X_train, y_train, random_state = 2):\n",
    "\n",
    "    # clone the model to have the exact same specification as the one initially trained\n",
    "    model_clone = clone(model)\n",
    "    # set random_state for comparability\n",
    "    model_clone.random_state = random_state\n",
    "    # training and scoring the benchmark model\n",
    "    model_clone.fit(X_train, y_train)\n",
    "    benchmark_score = cross_val_score(model_clone, X_train, y_train, cv=5, scoring='recall').mean()\n",
    "    \n",
    "    # list for storing feature importances\n",
    "    importances = []\n",
    "\n",
    "    # iterating over all columns and storing feature importance (difference between benchmark and new model)\n",
    "    for col in X_train.columns:\n",
    "        model_clone = clone(model)\n",
    "        model_clone.random_state = random_state\n",
    "        model_clone.fit(X_train.drop(col, axis = 1), y_train)\n",
    "        drop_col_score = cross_val_score(model_clone, X_train.drop(col, axis = 1), \n",
    "                                         y_train, cv=5, scoring='recall').mean()\n",
    "        importances.append(benchmark_score - drop_col_score)\n",
    "\n",
    "    importances_df = pd.DataFrame({\"feature_importance\": importances,\n",
    "              \"feature_name\": X_train.columns.values})\n",
    "    return importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data = drop_col_feat_imp(rf, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# feature_importance = rf.feature_importances_\n",
    "# fea_data = pd.DataFrame({\"feature_importance\": feature_importance,\n",
    "#               \"feature_name\": X_train.columns.values})\n",
    "\n",
    "fea_data_sort = fea_data.sort_values(by='feature_importance',ascending=False)\n",
    "pos = np.arange(fea_data_sort.shape[0])+.5\n",
    "\n",
    "features_list = X_train.columns.values\n",
    "\n",
    "figure(num=None, figsize=(4, 17), dpi=300)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "plt.barh(pos, fea_data_sort.feature_importance[::-1], align='center')\n",
    "plt.yticks(pos, fea_data_sort.feature_name[::-1])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "# plt.savefig('./figure/all_feature_VariableImportance.tif', bbox_inches='tight', dpi=600, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = rf.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_test)[:,1]\n",
    "thresh = 0.5\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity, rf_train_f1 =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "rf_valid_auc, rf_valid_accuracy, rf_valid_recall, rf_valid_precision, rf_valid_specificity, rf_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = pd.DataFrame(\n",
    "    {'data_set':['Train','Test'] * 6,\n",
    "     'evaluator': ['AUC', 'AUC', 'accuracy', 'accuracy', 'recall', 'recall', \n",
    "                   'precision', 'precision', 'specificty', 'specificty', \n",
    "                   'f1_socre', 'f1_socre'],\n",
    "     'value': [rf_train_auc, rf_valid_auc, rf_train_accuracy, rf_valid_accuracy,\n",
    "              rf_train_recall, rf_valid_recall, rf_train_precision, rf_valid_precision,\n",
    "              rf_train_specificity, rf_valid_specificity, rf_train_f1, rf_test_f1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "# 更改字体字号 10.5=五号字\n",
    "rcParams['font.size']=20\n",
    "rcParams['svg.fonttype']='none'\n",
    "rcParams['font.sans-serif']=['Times New Roman']\n",
    "rcParams['mathtext.fontset']='stix'\n",
    "rcParams['axes.grid']=True\n",
    "rcParams['axes.axisbelow']=True\n",
    "rcParams['grid.linestyle']='--'\n",
    "rcParams['xtick.direction']='in'\n",
    "rcParams['ytick.direction']='in'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "feat_labels = X_train.columns.values\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(\"%2d) %-*s %f\" % (f + 1, 30, feat_labels[indices[f]], importances[indices[f]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_importance = rf.feature_importances_\n",
    "fea_data = pd.DataFrame({\"feature_importance\": feature_importance,\n",
    "              \"feature_name\": X_train.columns.values})\n",
    "\n",
    "fea_data_sort = fea_data.sort_values(by='feature_importance',ascending=False)\n",
    "pos = np.arange(fea_data_sort.shape[0])+.5\n",
    "\n",
    "features_list = X_train.columns.values\n",
    "\n",
    "figure(num=None, figsize=(4, 17), dpi=300)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.barh(pos, fea_data_sort.feature_importance[::-1], align='center')\n",
    "plt.yticks(pos, fea_data_sort.feature_name[::-1])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.savefig('./figure/all_feature_VariableImportance.tif', bbox_inches='tight', dpi=600, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 随机森林是无法很好的处理分类变量的，会倾向于类别多的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf.feature_importances_\n",
    "fea_data = pd.DataFrame({\"feature_importance\": feature_importance,\n",
    "              \"feature_name\": X_train.columns.values})\n",
    "\n",
    "fea_data_sort = fea_data.sort_values(by='feature_importance',ascending=False)[:20]\n",
    "pos = np.arange(fea_data_sort.shape[0])+.5\n",
    "\n",
    "# features_list = X_train.columns.values\n",
    "\n",
    "figure(num=None, figsize=(4, 7), dpi=300)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.barh(pos, fea_data_sort.feature_importance[::-1], align='center')\n",
    "plt.yticks(pos, fea_data_sort.feature_name[::-1])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.savefig('./figure/all_feature_VariableImportance_20.tif', bbox_inches='tight', dpi=600, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)    # 定义分成几个组\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "target = df.expire_flag.values\n",
    "data = df.drop(['expire_flag'], axis=1).values\n",
    "figure(num=None, figsize=(7, 6), dpi=300)\n",
    "# plt.style.use(\"bmh\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "## 确定最佳阈值\n",
    "right_index = (mean_tpr + (1 - mean_fpr) - 1).tolist()\n",
    "index = right_index.index(max(right_index))\n",
    "\n",
    "tpr_val = mean_tpr[index]\n",
    "fpr_val = mean_fpr[index]\n",
    "\n",
    "# 画ROC\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "         lw=2)\n",
    "\n",
    "# 添加最佳截断值点\n",
    "plt.plot([fpr_val], [tpr_val], 'ro',)\n",
    "plt.annotate('('+'%0.3f'%fpr_val+', '+'%0.3f'%tpr_val+')',\n",
    "             xy=(fpr_val,tpr_val),xytext=(fpr_val+0.01,tpr_val+0.01))\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='darkgray', alpha=.3,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.savefig('./figure/All_feature_10_fold_ROC.tif', dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "from scipy import interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)    # 定义分成几个组\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "precisions = []\n",
    "prs = []\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "target = df.expire_flag.values\n",
    "data = df.drop(['expire_flag'], axis=1).values\n",
    "figure(num=None, figsize=(7, 6), dpi=300)\n",
    "# plt.style.use(\"bmh\")\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Compute ROC curve and area the curve\n",
    "    precision, recall, _ = precision_recall_curve(y_test, probas_)\n",
    "    auprc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, lw=1, alpha=0.3, label='PR fold %d (AUPRC = %0.3f)' % (i, auprc))\n",
    "    \n",
    "#     print(\"recall: \", recall.shape)\n",
    "#     print(\"precision: \", precision.shape)\n",
    "#     print(np.interp(mean_recall, recall, precision))\n",
    "    precisions.append(interpolate.interp1d(recall, precision)(mean_recall))\n",
    "    precisions[-1][0] = 1.0\n",
    "    prs.append(auprc)\n",
    "   \n",
    "    i += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_precision = np.mean(precisions, axis=0)\n",
    "mean_precision[-1] = 0.0\n",
    "mean_pr = auc(mean_recall, mean_precision)\n",
    "std_pr = np.std(prs)\n",
    "\n",
    "# 画ROC\n",
    "plt.plot(mean_recall, mean_precision, color='b',\n",
    "         label=r'Mean PR (AUPRC = %0.3f $\\pm$ %0.3f)' % (mean_pr, std_pr),\n",
    "         lw=2)\n",
    "\n",
    "# 添加平衡点\n",
    "ba_point = 0.750\n",
    "plt.plot([ba_point], [ba_point], 'ro',)\n",
    "plt.annotate('(balance: '+'%0.3f'%ba_point+')',\n",
    "             xy=(ba_point,ba_point),xytext=(ba_point+0.01,ba_point+0.01))\n",
    "\n",
    "std_precision = np.std(precisions, axis=0)\n",
    "precisions_upper = np.minimum(mean_precision + std_precision, 1)\n",
    "precisions_lower = np.maximum(mean_precision - std_precision, 0)\n",
    "\n",
    "plt.fill_between(mean_recall, precisions_lower, precisions_upper, color='darkgray', alpha=.3,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR')\n",
    "plt.legend(loc=\"lower left\", fontsize=12)\n",
    "plt.savefig('./figure/All_feature_10_fold_PR.tif', dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./use_df.csv')\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = train_data.expire_flag\n",
    "X_train = train_data.drop(['expire_flag'], axis=1)\n",
    "\n",
    "y_test = test_data.expire_flag\n",
    "X_test = test_data.drop(['expire_flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "\n",
    "alphas = 10**np.linspace(-4, -2, 100)\n",
    "lasso_cofficients = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in alphas: \n",
    "    lasso = Lasso(alpha = alpha, normalize= True, max_iter= 10000) \n",
    "    lasso.fit(X_train, y_train) \n",
    "    lasso_cofficients.append(lasso.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pylab import mpl\n",
    "mpl.rcdefaults()\n",
    "plt.rcParams[ 'font.sans-serif'] = [ 'Microsoft YaHei']\n",
    "plt.rcParams[ 'axes.unicode_minus'] = False\n",
    "\n",
    "figure(num=None, figsize=(8, 5), dpi=300)\n",
    "\n",
    "plt.plot(alphas, lasso_cofficients, lw=2)\n",
    "plt.xscale( 'log')\n",
    "plt.axis( 'tight')\n",
    "plt.title( 'Relationship between alpha and LASSO regression coefficient')\n",
    "plt.xlabel( 'Log Alpha')\n",
    "plt.ylabel( 'Cofficients')\n",
    "plt.grid(axis=\"both\")\n",
    "plt.savefig('./figure/lasso.tif', dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(alphas = alphas, normalize= True, cv = 10)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "lasso_best_alpha = lasso_cv.alpha_\n",
    "lasso_best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha = lasso_best_alpha, normalize= True, max_iter= 10000)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "print(lasso.coef_)\n",
    "\n",
    "lasso_predict = lasso.predict(X_train)\n",
    "roc = roc_auc_score(y_train, lasso_predict)\n",
    "roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib\n",
    "def rmse_cv(model):\n",
    "    rmse= cross_val_score(model, X_train, y_train, scoring=\"roc_auc\", cv = 5)\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lasso = lasso\n",
    "print(model_lasso.alpha)\n",
    "print(model_lasso.coef_)\n",
    "\n",
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "print(rmse_cv(model_lasso).mean())\n",
    "num = int(sum(coef != 0) / 2)\n",
    "imp_coef = pd.concat([coef.sort_values().head(num),\n",
    "                     coef.sort_values().tail(num)])\n",
    "\n",
    "figure(num=None, figsize=(4, 8), dpi=300)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.grid(axis='both')\n",
    "plt.title(\"Coefficients in the Lasso Model\")\n",
    "plt.savefig('./figure/lasso_coefficients.tif', dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cols = coef[coef.values != 0].index.to_list()\n",
    "lasso_cols.append('expire_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lasso_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = ['Age', 'Sex'\n",
    "            'BMI', 'HR', 'Glucose','SysBP',\n",
    "            'CK', \n",
    "            'APSIII', \n",
    "            'Creatinine', 'eGFR', 'UrineOutput', \n",
    "            'RDW', 'Albumin', 'Lymphocytes', \n",
    "            'AG', 'Potassium', 'Sodium', 'Chloride', 'Platlet', \n",
    "            'Hemoglobin',\n",
    "            'expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame(df, columns=new_cols)\n",
    "train_data, test_data = train_test_split(lasso_df, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = train_data.expire_flag\n",
    "X_train = train_data.drop(['expire_flag'], axis=1)\n",
    "\n",
    "y_test = test_data.expire_flag\n",
    "X_test = test_data.drop(['expire_flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(n_estimators, min_samples_split, max_depth):\n",
    "    val = cross_val_score(\n",
    "        RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        ), X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "rf_bo = BayesianOptimization(\n",
    "    rf_cv,\n",
    "    {'n_estimators': (10, 1000),\n",
    "     'min_samples_split': (2, 10),\n",
    "#      'max_features': (0.001, 0.999),\n",
    "     'max_depth': (2, 150)}\n",
    ")\n",
    "\n",
    "rf_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features = rf_bo.max['params']['max_features']\n",
    "max_depth = rf_bo.max['params']['max_depth']\n",
    "n_estimators = rf_bo.max['params']['n_estimators']\n",
    "min_samples_split = rf_bo.max['params']['min_samples_split']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = rf.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_test)[:,1]\n",
    "thresh = 0.5\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "rf_train_auc, rf_train_accuracy, rf_train_recall, rf_train_precision, rf_train_specificity, rf_train_f1 =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "lasso_rf_valid_auc, lasso_rf_valid_accuracy, lasso_rf_valid_recall, lasso_rf_valid_precision, lasso_rf_valid_specificity, lasso_rf_test_f1 = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 比较全变量和lasso选择变量的结果\n",
    "labels = ['AUC', 'Accuracy', 'Recall', 'Precision', 'Specificity', 'F1_Score'] \n",
    "lasso_means = [lasso_rf_valid_auc.round(2), lasso_rf_valid_accuracy.round(2), lasso_rf_valid_recall.round(2), lasso_rf_valid_precision.round(2), np.float64(lasso_rf_valid_specificity).round(2), lasso_rf_test_f1.round(2)] \n",
    "all_means = [rf_valid_auc.round(2), rf_valid_accuracy.round(2), rf_valid_recall.round(2), rf_valid_precision.round(2), np.float64(rf_valid_specificity).round(2), rf_test_f1.round(2)]  \n",
    "x = np.arange(len(labels))  \n",
    "\n",
    "# the label locations \n",
    "width = 0.35  \n",
    "plt.rcParams['figure.figsize'] = (10.0, 4.0) # 设置figure_size尺寸\n",
    "plt.rcParams['font.sans-serif']=['Times New Roman']\n",
    "plt.rcParams['font.size']=14\n",
    "plt.rcParams['svg.fonttype']='none'\n",
    "\n",
    "\n",
    "rects1 = plt.bar(x - width/2, all_means, width, label='All') \n",
    "rects2 = plt.bar(x + width/2, lasso_means, width, label='Lasso')  \n",
    "# Add some text for labels, title and custom x-axis tick labels, etc. \n",
    "\n",
    "\n",
    "def autolabel(rects):     \n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"     \n",
    "    for rect in rects:         \n",
    "        height = rect.get_height()         \n",
    "        plt.annotate('{}'.format(height),                     \n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),                     \n",
    "                    xytext=(0, 3),  # 3 points vertical offset                     \n",
    "                    textcoords=\"offset points\",                     \n",
    "                    ha='center', \n",
    "                    va='bottom')  \n",
    "autolabel(rects1) \n",
    "autolabel(rects2) \n",
    "ax1=plt.gca()\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.spines['right'].set_visible(False)\n",
    "\n",
    "ax1.set_xlabel('Score', fontsize=16)\n",
    "ax1.set_ylabel('Evaluation Index', fontsize=16)\n",
    "# plt.title(\"Random Forest \", fontsize=16)\n",
    "plt.xticks(ticks=x, labels=labels, rotation=45, fontsize=16) \n",
    "plt.yticks(fontsize=16) \n",
    "\n",
    "plt.legend(loc='lower right', fontsize =16)   \n",
    "\n",
    "\n",
    "plt.savefig('./figure/RF_ALL_Lasso_Evaluate.tif', bbox_inches='tight', dpi=600, transparent=True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vari Impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature_importance = rf.feature_importances_\n",
    "fea_data = pd.DataFrame({\"feature_importance\": feature_importance,\n",
    "              \"feature_name\": X_train.columns.values})\n",
    "\n",
    "fea_data_sort = fea_data.sort_values(by='feature_importance',ascending=False)\n",
    "pos = np.arange(fea_data_sort.shape[0])+.5\n",
    "\n",
    "features_list = X_train.columns.values\n",
    "\n",
    "figure(num=None, figsize=(4, 7), dpi=300)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.barh(pos, fea_data_sort.feature_importance[::-1], align='center')\n",
    "plt.yticks(pos, fea_data_sort.feature_name[::-1])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.savefig('./figure/lasso_feature_VariableImportance.tif', bbox_inches='tight', dpi=600, transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = rf.feature_importances_\n",
    "fea_data = pd.DataFrame({\"feature_importance\": feature_importance,\n",
    "              \"feature_name\": X_train.columns.values})\n",
    "\n",
    "fea_data_sort = fea_data.sort_values(by='feature_importance',ascending=False)[:20]\n",
    "pos = np.arange(fea_data_sort.shape[0])+.5\n",
    "\n",
    "# features_list = X_train.columns.values\n",
    "\n",
    "figure(num=None, figsize=(4, 7), dpi=300)\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "plt.barh(pos, fea_data_sort.feature_importance[::-1], align='center')\n",
    "plt.yticks(pos, fea_data_sort.feature_name[::-1])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.title('Variable Importance')\n",
    "plt.savefig('./figure/Lasso_feature_VariableImportance_20.pdf', bbox_inches='tight', dpi=600, transparent=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run classifier with cross-validation and plot ROC curves\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)    # 定义分成几个组\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "#             max_features=min(max_features, 0.999), # float\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "target = df.expire_flag.values\n",
    "data = df.drop(['expire_flag'], axis=1).values\n",
    "figure(num=None, figsize=(7, 6), dpi=300)\n",
    "# plt.style.use(\"bmh\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "    \n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probas_)\n",
    "    tprs.append(np.interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.3f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "\n",
    "## 确定最佳阈值\n",
    "right_index = (mean_tpr + (1 - mean_fpr) - 1).tolist()\n",
    "index = right_index.index(max(right_index))\n",
    "\n",
    "tpr_val = mean_tpr[index]\n",
    "fpr_val = mean_fpr[index]\n",
    "\n",
    "# 画ROC\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.3f $\\pm$ %0.3f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "# 添加最佳截断值点\n",
    "plt.plot([fpr_val], [tpr_val], 'ro',)\n",
    "plt.annotate('('+'%0.3f'%fpr_val+', '+'%0.3f'%tpr_val+')',\n",
    "             xy=(fpr_val,tpr_val),xytext=(fpr_val+0.01,tpr_val+0.01))\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='darkgray', alpha=.3,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC')\n",
    "plt.legend(loc=\"lower right\", fontsize=12)\n",
    "plt.savefig('./figure/Lasso_10_fold_ROC.tif', dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "precisions = []\n",
    "prs = []\n",
    "mean_recall = np.linspace(0, 1, 100)\n",
    "\n",
    "target = df.expire_flag.values\n",
    "data = df.drop(['expire_flag'], axis=1).values\n",
    "figure(num=None, figsize=(7, 6), dpi=300)\n",
    "\n",
    "i = 0\n",
    "for train_index, test_index in kf.split(data):\n",
    "    X_train, X_test = data[train_index], data[test_index]\n",
    "    y_train, y_test = target[train_index], target[test_index]\n",
    "    probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "    \n",
    "    precision, recall, _ = precision_recall_curve(y_test, probas_)\n",
    "    auprc = auc(recall, precision)\n",
    "    plt.plot(recall, precision, lw=1, alpha=0.3, label='PR fold %d (AUPRC = %0.3f)' % (i, auprc))\n",
    "\n",
    "    precisions.append(interpolate.interp1d(recall, precision)(mean_recall))\n",
    "    precisions[-1][0] = 1.0\n",
    "    prs.append(auprc)\n",
    "   \n",
    "    i += 1\n",
    "\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Chance', alpha=.8)\n",
    "\n",
    "mean_precision = np.mean(precisions, axis=0)\n",
    "mean_precision[-1] = 0.0\n",
    "mean_pr = auc(mean_recall, mean_precision)\n",
    "std_pr = np.std(prs)\n",
    "\n",
    "plt.plot(mean_recall, mean_precision, color='b',\n",
    "         label=r'Mean PR (AUPRC = %0.3f $\\pm$ %0.3f)' % (mean_pr, std_pr),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "ba_point = 0.751\n",
    "plt.plot([ba_point], [ba_point], 'ro',)\n",
    "plt.annotate('(balance: '+'%0.3f'%ba_point+')',\n",
    "             xy=(ba_point,ba_point),xytext=(ba_point+0.01,ba_point+0.01))\n",
    "\n",
    "std_precision = np.std(precisions, axis=0)\n",
    "precisions_upper = np.minimum(mean_precision + std_precision, 1)\n",
    "precisions_lower = np.maximum(mean_precision - std_precision, 0)\n",
    "\n",
    "plt.fill_between(mean_recall, precisions_lower, precisions_upper, color='darkgray', alpha=.3,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('PR')\n",
    "plt.legend(loc=\"lower left\", fontsize=12)\n",
    "plt.savefig('./figure/Lasso_10_fold_PR.tif', dpi=600, bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso_SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./use_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cols = ['Age', 'Sex',\n",
    "            'BMI', 'HR', 'Glucose','SysBP',\n",
    "            'CK', \n",
    "            'APSIII', \n",
    "            'Creatinine', 'eGFR', 'UrineOutput', \n",
    "            'RDW', 'Albumin', 'Lymphocytes', \n",
    "            'AG', 'Potassium', 'Sodium', 'Chloride', 'Platlet', \n",
    "            'Hemoglobin',\n",
    "            'expire_flag']\n",
    "len(con_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_df = pd.DataFrame(df, columns=con_cols)\n",
    "train_data, test_data = train_test_split(lasso_df, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = train_data.expire_flag\n",
    "X_train = train_data.drop(['expire_flag'], axis=1)\n",
    "\n",
    "y_test = test_data.expire_flag\n",
    "X_test = test_data.drop(['expire_flag'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_cv(n_estimators, min_samples_split, max_depth):\n",
    "    val = cross_val_score(\n",
    "        RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        ), X_train, y_train, scoring='roc_auc', cv=5\n",
    "    ).mean()\n",
    "    return val\n",
    "\n",
    "rf_bo = BayesianOptimization(\n",
    "    rf_cv,\n",
    "    {'n_estimators': (10, 1000),\n",
    "     'min_samples_split': (2, 10),\n",
    "     'max_depth': (2, 150)}\n",
    ")\n",
    "\n",
    "rf_bo.maximize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 40\n",
    "n_estimators = 944\n",
    "min_samples_split = 2\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=int(n_estimators),\n",
    "            min_samples_split=int(min_samples_split),\n",
    "            max_depth=int(max_depth),\n",
    "            random_state=2\n",
    "        )\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "y_valid_preds = rf.predict_proba(X_test)[:,1]\n",
    "rf_valid_auc_base = roc_auc_score(y_test, y_valid_preds)\n",
    "\n",
    "print('Validation AUC:%.3f'%(rf_valid_auc_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = rf.predict_proba(X_train)[:,1]\n",
    "y_valid_preds = rf.predict_proba(X_test)[:,1]\n",
    "thresh = 0.5\n",
    "print('Random Forest')\n",
    "print('Training:')\n",
    "_, _, _, _, _, _ =print_report(y_train,y_train_preds, thresh)\n",
    "print('Validation:')\n",
    "_, _, _, _, _, _ = print_report(y_test,y_valid_preds, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.Explainer(rf)\n",
    "shap_values = explainer.shap_values(X_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waterfall_shap = explainer(test_data.loc[test_data['expire_flag'] == 1][:20].drop(['expire_flag'], axis=1))[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    fig = plt.figure(figsize=(6,4))\n",
    "\n",
    "    shap.plots.waterfall(waterfall_shap[i], max_display=10, show=False)\n",
    "    \n",
    "    fig.set_facecolor('white')\n",
    "    fig.savefig('./figure/waterfall_label_1_%s.tif'%str(i), bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cols = ['Age', \n",
    "            'BMI', 'HR', 'Glucose','SysBP',\n",
    "            'CK', \n",
    "            'APSIII', \n",
    "            'Creatinine', 'eGFR', 'UrineOutput', \n",
    "            'RDW', 'Albumin', 'Lymphocytes', \n",
    "            'AG', 'Potassium', 'Sodium', 'Chloride', 'Platlet', \n",
    "            'Hemoglobin',\n",
    "            'expire_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_list = [['APSIII', 'Age'], \n",
    "                    ['APSIII', 'Sex'],\n",
    "                    ['SysBP','APSIII'],\n",
    "                    ['APSIII', 'eGFR'], \n",
    "                    ['RDW', 'APSIII'],\n",
    "                    ['Albumin', 'APSIII'],\n",
    "                    ['Lymphocytes', 'APSIII'],\n",
    "                    ['Sodium', 'APSIII'],\n",
    "                    ['AG', 'APSIII'], \n",
    "['Potassium', 'APSIII'], ['Chloride', 'APSIII'], ['Hemoglobin', 'APSIII']\n",
    "                   ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inter in interaction_list:\n",
    "    print(inter)\n",
    "    fig = plt.figure(figsize=(6,4)) \n",
    "    ax = fig.subplots(1,1)\n",
    "\n",
    "    ax.axhline(y=0, ls=\"-\",c=\"red\", linewidth=2)\n",
    "    ax.grid(linewidth=1,alpha=0.3)  \n",
    "    shap.dependence_plot(inter[0], shap_values, X_train, interaction_index=inter[1], ax=ax, show=False)\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "    name = \"_\".join(inter)\n",
    "    fig.savefig('./figure/interction_%s.tif'%name, bbox_inches=\"tight\", dpi=600, transparent=True)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(6,4)) \n",
    "    ax = fig.subplots(1,1)\n",
    "\n",
    "    ax.axhline(y=0, ls=\"-\",c=\"red\", linewidth=2)\n",
    "    ax.grid(linewidth=1,alpha=0.3)  \n",
    "    shap.dependence_plot(inter[1], shap_values, X_train, interaction_index=inter[0], ax=ax, show=False)\n",
    "\n",
    "    fig.set_facecolor('white')\n",
    "    inter.reverse()\n",
    "    name = \"_\".join(inter)\n",
    "    fig.savefig('./figure/interction_%s.tif'%name, bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot('Creatinine', shap_values, X_test, \n",
    "                     interaction_index='AG', \n",
    "                     show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "print('n: %d, y: %d'%(n, y_test.iloc[n]))\n",
    "# shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[n], X_test.iloc[n], matplotlib=True, show=False)\n",
    "plt.savefig('./figure/force_plot_label1.tif', bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "print('n: %d, y: %d'%(n, y_test.iloc[n]))\n",
    "shap.initjs()\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[n], X_test.iloc[n], matplotlib=True, show=False)\n",
    "plt.savefig('./figure/force_plot_label0.tif', bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
    "plt.title('Feature importance of SHAP')\n",
    "plt.savefig('./figure/summary_plot_bar.tif', bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_test, show=False)\n",
    "plt.title('SHAP beeswarm plot')\n",
    "plt.savefig('./figure/summary_plot.tif', bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_cols.remove('expire_flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "rcParams['font.size']=20\n",
    "rcParams['svg.fonttype']='none'\n",
    "rcParams['font.sans-serif']=['Times New Roman']\n",
    "rcParams['mathtext.fontset']='stix'\n",
    "rcParams['axes.grid']=True\n",
    "rcParams['axes.axisbelow']=True\n",
    "rcParams['grid.linestyle']='--'\n",
    "rcParams['xtick.direction']='in'\n",
    "rcParams['ytick.direction']='in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for feature_ in con_cols:\n",
    "\n",
    "    fig = plt.figure(figsize=(6,4)) \n",
    "\n",
    "    idx = np.where(X_test.columns==feature_)[0][0]\n",
    "    x = X_test.iloc[:,idx]\n",
    "    y_sv = shap_values[:,idx]\n",
    "    lowess = sm.nonparametric.lowess(y_sv, x, frac=.4)  \n",
    "\n",
    "    ax = fig.subplots(1,1)\n",
    "\n",
    "    ax.plot(*list(zip(*lowess)), color=\"red\", ls=':', linewidth=4)\n",
    "    ax.axhline(y=0, ls=\"-\",c=\"red\", linewidth=2)\n",
    "#     ax.set_title('%s SHAP dependence plot'%feature_)\n",
    "    ax.grid(linewidth=1,alpha=0.3)  \n",
    "    # ax.set_xticklabels(ax.get_xticklabels(),fontsize=3)\n",
    "\n",
    "    shap.dependence_plot(feature_, shap_values, X_test, ax=ax, interaction_index=None, show=False)\n",
    "    \n",
    "    fig.set_facecolor('white')\n",
    "    fig.savefig('./figure/dependence_plot_%s.tif'%feature_, bbox_inches=\"tight\", dpi=600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "fr",
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
